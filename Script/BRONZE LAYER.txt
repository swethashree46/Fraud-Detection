BRONZE LAYER 

%scala

import org.apache.spark.eventhubs._
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._
import org.apache.spark.sql.streaming.Trigger


val txnSchema = StructType(Array(
  StructField("transaction_id", StringType, true),
  StructField("customer_id", StringType, true),
  StructField("merchant_id", StringType, true),
  StructField("timestamp", TimestampType, true),
  StructField("amount", DoubleType, true),
  StructField("transaction_type", StringType, true),
  StructField("transaction_city", StringType, true),
  StructField("device_id", StringType, true),
  StructField("is_fraud", IntegerType, true)
))


// 2. Event Hub configuration
val eventHubConnectionString = "<AZURE_EVENT_HUB_CONNECTION_STRING>"
val eventHubConfig = EventHubsConf(eventHubConnectionString)
  .setConsumerGroup("$Default")


val rawStream = spark.readStream
  .format("eventhubs")
  .options(eventHubConfig.toMap)
  .load()

val txnStream = rawStream
  .selectExpr("cast(body as string) as json")
  .select(from_json(col("json"), txnSchema).as("data"))
  .select("data.*")
  .withColumn("is_fraud", col("is_fraud").cast("integer"))


txnStream.writeStream
  .format("delta")
  .option("checkpointLocation", "/mnt/checkpoints/bronze_transactions")
  .option("mergeSchema", "true")
  .outputMode("append")
  .table("fraud_detection.bronze_transactions")
  


%scala
import org.apache.spark.eventhubs._
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._


// Customer schema
val custSchema = StructType(Array(
  StructField("customer_id", StringType, true),
  StructField("customer_name", StringType, true),
  StructField("city", StringType, true),
  StructField("device_id", StringType, true)
))

// Event Hub configuration for customers (use correct EntityPath)
val eventHubConnectionStringCust = "<AZURE_EVENT_HUB_CONNECTION_STRING>"
val eventHubConfigCust = EventHubsConf(eventHubConnectionStringCust)
  .setConsumerGroup("$Default")

// Read stream from Event Hub for customers
val rawcustStream = spark.readStream
  .format("eventhubs")
  .options(eventHubConfigCust.toMap)
  .load()

// Parse JSON and rename city
val custStream = rawcustStream
  .selectExpr("cast(body as string) as json")
  .select(from_json(col("json"), custSchema).as("data"))
  .select("data.*")
  .withColumnRenamed("city", "customer_city")

// Write to Bronze table
custStream.writeStream
  .format("delta")
  .option("checkpointLocation", "/mnt/checkpoints/bronze_customers_new") // Use a new, unique path
  .option("mergeSchema", "true")
  .outputMode("append")
  .table("fraud_detection.bronze_customers")


  %scala

import org.apache.spark.eventhubs._
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._
import org.apache.spark.sql.streaming.Trigger


val merchSchema = StructType(Array(
  
  StructField("merchant_id", StringType, true),
  StructField("merchant_name", StringType, true),
  StructField("merchant_category", StringType, true),
  StructField("city", StringType, true)
))


// 2. Event Hub configuration
val eventHubConnectionString = "<AZURE_EVENT_HUB_CONNECTION_STRING>"
val eventHubConfig = EventHubsConf(eventHubConnectionString)
  .setConsumerGroup("$Default")


val rawmerchStream = spark.readStream
  .format("eventhubs")
  .options(eventHubConfig.toMap)
  .load()

val merchStream = rawStream
  .selectExpr("cast(body as string) as json")
  .select(from_json(col("json"), merchSchema).as("data"))
  .select("data.*")
  .withColumnRenamed("city", "merchant_city")


merchStream.writeStream
  .format("delta")
  .option("checkpointLocation", "/mnt/checkpoints/bronze_merchants")
  .option("mergeSchema", "true")
  .outputMode("append")
  .table("fraud_detection.bronze_merchants")
  

